{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxp75OuOKsod"
   },
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsstcPVGKsoh"
   },
   "source": [
    "# COGS 108 - EDA Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN7nnxMXKsoh"
   },
   "source": [
    "# Names\n",
    "\n",
    "- Celeste Walstrom-Vangor\n",
    "- Rui Wang\n",
    "- Jheel Gandhi\n",
    "- Howard Ma\n",
    "- Kenny Qiu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-MJWoy1Ksoi"
   },
   "source": [
    "# **Research Question**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XvtCVa_Ksoi"
   },
   "source": [
    "Can we predict the Letterboxd ratings for upcoming movies based solely on actors in those movies and the ratings of their previous films, focusing on the ratings of Gen Z?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY98TkGTKsoi"
   },
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLKJ-FeSKsoi"
   },
   "source": [
    "By figuring out if there is a correlation between actors' previous movies and their forcasted Letterboxd movie rating, we will be able to determine whether a new movie can be determined as highly rated based only on the actors who are starring in it. Although there are many factors that go into the ratings of a movie, if we can create an accurate algorithm that focuses on actors alone it will be highly convinient so people can determine whether a movie will be highly rated before going to see it. As busy college students, we want to dedicate our time to helping people avoid going to a low rated movies before the ratings come out. If we can find a correlation between the ratings of previous movies with actors and the ratings of new movies with those same actors it could save people a lot of time.\n",
    "\n",
    "Here are some prior work we found online:\n",
    "\n",
    "1. Vox Analysis on the the actors and actresses who most consistently appear in terrible movies\n",
    "\n",
    "  One previous analysis from Vox was done on the actors who starred in the best and worst rated films based on metacritic. From which they restricted the data set to only include actors that meet the following criteria:\n",
    "    1. The actor/actress must have performed in at least 10 films (writing, directing, and producing credits were omitted).\n",
    "    2. At least one of these films had to have grossed $30 million or more at the box office, adjusted for inflation.\n",
    "    3. At least one of these films had to be within the past five years (we only wanted semi-active performers).\n",
    "\n",
    "  From the blog post analysis of the top 10 worst rated actors, we can see familiar names like Adam Sandler and Jennifer Love Hewitt who are often known for being in worse rated movies. On the other hand, for the top 10 best rated actors, familiar names that are known for having good movies like Leonardo Di Caprio and Jennifer Lawerence make the list.\n",
    "\n",
    "  Something interesting to note is that genres like action and comedy are rated more harshly than genres like documentaries and drama. This is hypothesized to be due to the subjective nature of comedy films.\n",
    "\n",
    "  This analysis does only look at single actors rather than taking into account all the actors in a film, but it does conclude that there’s at least some correlation between an actor and their movie’s rating.\n",
    "\n",
    "2.\n",
    "The Hustle - The actors who are the best (and worst) at their job:\n",
    "\n",
    "  The Hustle did a similar analysis on actors and the critical ratings they get.\n",
    "  Here are the datasets used by the blog post:\n",
    "    1. Average Metacritic scores (a measurement of critical ratings) across all films for 35k+ actors\n",
    "    2. Average domestic box office data across all films an actor has played a prominent role in over their career\n",
    "\n",
    "  They chose domestic box office because international films are biased towards franchise films, and the box office dataset is not adjusted for inflation so it favors newer films.\n",
    "\n",
    "  Similar to the first analysis, critics are biased against comedy and love films, with those films getting lower than average ratings.\n",
    "\n",
    "  They also included a beloved actors matrix where they plotted the average box office of an actor (how loved they are by the audience) with the average metacritic score (how loved they are by the critics).\n",
    "\n",
    "  They then did a composite score taking into account both the percentiles of the box office and their metacritic. In this final list, actors like Leonardo DiCaprio and Tom Hanks make the list of the best combination and actors like Bella Thorne and Chad Michael Murray make the list of the worst combination.\n",
    "\n",
    "  This analysis also seems to support the fact that some actors are more likely to have better rated movies, but this study only takes in single actors as well as the first analysis did, so there’s more work to be done on analyzing multiple actors for a single film.\n",
    "\n",
    "  Something to note here is that just because a movie has bad critic ratings does not mean that the audience doesn’t like it, as supported by big box offices for some of the worst rated actors.\n",
    "\n",
    "\n",
    "\n",
    "References:\n",
    "* https://www.vox.com/2016/4/11/11381206/worst-actors-hollywood\n",
    "* https://thehustle.co/the-actors-who-are-the-best-and-worst-at-their-job/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isi8Ikl7Ksoj"
   },
   "source": [
    "# **Hypothesis**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzEKerE7Ksoj"
   },
   "source": [
    "We predict that there exists a positive correlation between the Letterboxd ratings of past movies with the top 1000 most relevant actors and the ratings of their upcoming films. This assumption stems from the idea that actors with a history of highly rated performances are likely to continue appearing in well-received films, contributing to positive Letterboxd reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vwYiAtdm4qW"
   },
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQExPTH-m4qW"
   },
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:actors\n",
    "  - Link to the dataset:https://www.kaggle.com/datasets/gsimonx37/letterboxd?select=actors.csv\n",
    "  - Number of observations:5523327\n",
    "  - Number of variables:2\n",
    "- Dataset #2\n",
    "  - Dataset Name:genres\n",
    "  - Link to the dataset: https://www.kaggle.com/datasets/gsimonx37/letterboxd?select=genres.csv\n",
    "  - Number of observations:990770\n",
    "  - Number of variables:2\n",
    "- Dataset #3\n",
    "  - Dataset Name:language\n",
    "  - Link to the dataset: https://www.kaggle.com/datasets/gsimonx37/letterboxd?select=languages.csv\n",
    "  - Number of observations:988826\n",
    "  - Number of variables:3\n",
    "- Dataset #4\n",
    "  - Dataset Name:movies\n",
    "  - Link to the dataset: https://www.kaggle.com/datasets/gsimonx37/letterboxd?select=movies.csv\n",
    "  - Number of observations:896400\n",
    "  - Number of variables:7\n",
    "\n",
    "\n",
    "We are planning to utilize four datasets: **actors.csv**, **genres.csv**, **language.csv**, and **movies.csv**.\n",
    "\n",
    "**actors.csv**: This dataset comprises two variables: **id** and **name**. The **id** column contains numerous instances of identical numbers each associated with different **name** entries, representing actors. We intend to consolidate identical **id** numbers and compile a corresponding list of actor names. This process will involve groupby() to handle repeated **id** values.\n",
    "\n",
    "**genres.csv**: Similar to the **actors.csv**, it contains two variables: **id** and **genre**. We will merge identical **id** numbers, creating a comprehensive list of genres associated with each unique identifier. This dataset will help us understand the distribution of movie genres and their relationships with other variables.\n",
    "\n",
    "**language.csv**: This dataset includes three variables: **id**, **type**, and **language**. Our approach will not only groupby() the same **id** but also filter entries in the **type** column to retain only 'Language' and 'Primary language'.\n",
    "\n",
    "**movies.csv**: Containing seven variables, we plan to discard **tagline**, **description**, and **minute** from our analysis.  We will focus on **id**, **name**, **date**, and **rating**, which are more aligned with our objectives.\n",
    "\n",
    "For data cleaning, we will include movies with a **date** later than 1970, with 'English' among their languages, and we will eliminate any datas containing **'NaN'** to maintain data integrity.\n",
    "\n",
    "The combination of these datasets will involve merging based on the **id** field, ensuring that each movie's data is enriched with corresponding actors, genres, and language information. The final dataset will feature variables such as **id**, **movie**, **date**, **rating**, **actors**, **genre**, **language**, and **director**. This cohesive dataset will form the foundation of our project's analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Onsj3MkBm4qW"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bPoPtVEm4qY"
   },
   "source": [
    "## Dataset # actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PTpeIBvFm4qY",
    "outputId": "7cd97a5a-b84c-4073-d1aa-80b8a601909d"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'actors.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1148/544531376.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactors_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'actors.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mactors_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'actors.csv'"
     ]
    }
   ],
   "source": [
    "actors_df = pd.read_csv('actors.csv')\n",
    "actors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwpgUYNzm4qZ"
   },
   "source": [
    "## Dataset # genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdKcUb5jm4qZ",
    "outputId": "2d368c73-ad42-4cf8-af97-c7d4a2736638"
   },
   "outputs": [],
   "source": [
    "genres_df = pd.read_csv('genres.csv')\n",
    "genres_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqFJvemhm4qa"
   },
   "source": [
    "## Dataset # language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nchXy8Ydm4qa",
    "outputId": "0578b553-bc3b-475e-f5c9-29f137663d60"
   },
   "outputs": [],
   "source": [
    "languages_df = pd.read_csv('languages.csv')\n",
    "languages_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqUzd0Lsm4qa"
   },
   "source": [
    "## Dataset # movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7zqsHrum4qa",
    "outputId": "de3c63bd-0a7a-4fa0-f3ac-5ea75735eb84"
   },
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('movies.csv')\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tMbNyvBAng9"
   },
   "source": [
    "# **EDA part 1: Data cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3cVIb9ZWmAl"
   },
   "source": [
    "Now our raw data consists of multiple datasets and isn't very clean, so we will need to do some wrangling. First let's load in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8802b96e"
   },
   "outputs": [],
   "source": [
    "# Imports dependencies\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chisquare, normaltest\n",
    "# Note: the statsmodels import may print out a 'FutureWarning'. Thats fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9118d8e7",
    "outputId": "c18bdafc-cf47-4e12-e5e6-51276cd0d0d0"
   },
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame\n",
    "actors_df = pd.read_csv('actors.csv')\n",
    "\n",
    "# Group by 'id' and create a list of 'name' for each group\n",
    "grouped_actors = actors_df.groupby('id')['name'].apply(list).reset_index()\n",
    "\n",
    "# Display the first few rows of the grouped DataFrame\n",
    "grouped_actors.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "062dc7e4",
    "outputId": "6e729192-3b54-49ef-ed13-035b4c902f7c"
   },
   "outputs": [],
   "source": [
    "# Read CSV file 'genres.csv' into DataFrame\n",
    "genres_df = pd.read_csv('genres.csv')\n",
    "\n",
    "# Group by 'id' and create a list of 'genre' for each group\n",
    "grouped_genres = genres_df.groupby('id')['genre'].apply(list).reset_index()\n",
    "\n",
    "# Display the first five rows of the grouped DataFrame\n",
    "grouped_genres.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "664af1aa",
    "outputId": "d91058f3-0a86-43e9-b7fa-eaba8dd6cb31"
   },
   "outputs": [],
   "source": [
    "# Read CSV file 'languages.csv' into DataFrame\n",
    "languages_df = pd.read_csv('languages.csv')\n",
    "\n",
    "# Filter rows where 'type' is either 'Language' or 'Primary language'\n",
    "filtered_languages_df = languages_df[languages_df['type'].isin(['Language', 'Primary language'])]\n",
    "\n",
    "# Display the first 20 rows of the filtered DataFrame\n",
    "filtered_languages_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "df48ddf9"
   },
   "outputs": [],
   "source": [
    "# Read CSV file 'movies.csv' into DataFrame\n",
    "movies_df = pd.read_csv('movies.csv')\n",
    "\n",
    "# Rename the 'name' column to 'movie' in DataFrame movies_df\n",
    "movies_df.rename(columns={'name': 'movie'}, inplace=True)\n",
    "\n",
    "# Merge movies_df with grouped_actors on the 'id' column using a left join\n",
    "merged_movies = pd.merge(movies_df, grouped_actors, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2122fe59"
   },
   "outputs": [],
   "source": [
    "# Merge merged_movies with grouped_genres on the 'id' column using a left join\n",
    "merged_movies_actors_genres = pd.merge(merged_movies, grouped_genres, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c09027ac",
    "outputId": "3493cc8e-7b14-4a9b-b75f-08034e94e531"
   },
   "outputs": [],
   "source": [
    "# Merge merged_movies_actors_genres with filtered_languages_df on the 'id' column using a left join\n",
    "merged_movies_actors_genres_languages = pd.merge(merged_movies_actors_genres, filtered_languages_df, on='id', how='left')\n",
    "\n",
    "# Display the first 5 rows of the merged DataFrame\n",
    "merged_movies_actors_genres_languages.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0672afd7"
   },
   "outputs": [],
   "source": [
    "# Read CSV file 'crew.csv' into DataFrame\n",
    "crew_df = pd.read_csv('crew.csv')\n",
    "\n",
    "# Filter rows where 'role' is 'Director'\n",
    "directors_df = crew_df[crew_df['role'] == 'Director']\n",
    "\n",
    "# Rename the 'name' column to 'Director' in the filtered DataFrame\n",
    "directors_df.rename(columns={'name': 'Director'}, inplace=True)\n",
    "\n",
    "# Drop the 'role' column from the filtered DataFrame\n",
    "directors_df.drop(columns='role', inplace=True)\n",
    "\n",
    "# Display the first 5 rows of the directors DataFrame\n",
    "directors_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8062c288",
    "outputId": "dd527f0e-80e0-46bc-d6cd-8828ecd1e30c"
   },
   "outputs": [],
   "source": [
    "# Group directors_df by 'id' and create a list of 'Director' for each group\n",
    "grouped_directors = directors_df.groupby('id')['Director'].apply(list).reset_index()\n",
    "\n",
    "# Display the first 15 rows of the grouped DataFrame\n",
    "grouped_directors.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1a60cd5e",
    "outputId": "55ae8f26-821a-4cab-8a8c-915c4e0768dc"
   },
   "outputs": [],
   "source": [
    "# Merge merged_movies_actors_genres_languages with grouped_directors on the 'id' column using a left join\n",
    "total_merged_movies = pd.merge(merged_movies_actors_genres_languages, grouped_directors, on='id', how='left')\n",
    "\n",
    "# Display the first 5 rows of the merged DataFrame\n",
    "total_merged_movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78c47804",
    "outputId": "0f469d17-8c3f-41db-c43b-5604056a3a70",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_merged_movies.drop(columns=['tagline', 'description', 'minute', 'type'], inplace=True)\n",
    "total_merged_movies.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27ce29c6",
    "outputId": "6cc83054-e178-42cb-a16d-273e914824ec"
   },
   "outputs": [],
   "source": [
    "#We want to eliminate movies that are too old, and we decided that 1970 is a good year to draw the line\n",
    "total_merged_movies['date'] = pd.to_numeric(total_merged_movies['date'], errors='coerce')\n",
    "filtered_movies_df = total_merged_movies[total_merged_movies['date'] > 1970.0]\n",
    "filtered_movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "205e8fbf",
    "outputId": "a938dfbd-d386-4b17-b685-c23fb8ef936f"
   },
   "outputs": [],
   "source": [
    "filtered_movies_df = filtered_movies_df.dropna()\n",
    "filtered_movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd547eb1",
    "outputId": "c5846ed1-5ba6-49ee-b74c-e3595adf523e"
   },
   "outputs": [],
   "source": [
    "filtered_movies_eng_df = filtered_movies_df[filtered_movies_df['language'].apply(lambda x: 'English' in x)]\n",
    "filtered_movies_eng_df.to_csv('filtered_movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9htNGE-ZGjm"
   },
   "source": [
    "Now we have merged our loose datasets and dropped the null values, here's what the final dataset look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "knhK2QgYU59V",
    "outputId": "51fed59a-5c3d-4b33-9ce4-0b1796e041d1"
   },
   "outputs": [],
   "source": [
    "filtered_movies_df = pd.read_csv('filtered_movies.csv')\n",
    "filtered_movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ip1QhJeNAYr4"
   },
   "source": [
    "rename third column to make it easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5d-btH5LAYal"
   },
   "outputs": [],
   "source": [
    "filtered_movies_df = filtered_movies_df.rename(columns={'name': 'actors'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8Vu7ghTZuYK"
   },
   "source": [
    "Let's also drop all the null values in columns 'movie', 'rating', and 'actors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_ahglpaZDgGn",
    "outputId": "7f19c860-2341-426f-e21b-07659a927c6b"
   },
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in 'movie', 'rating', or 'actors' columns\n",
    "filtered_movies_df = filtered_movies_df.dropna(subset=['movie', 'rating', 'actors'])\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "filtered_movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTQ2GLAW-jv4"
   },
   "source": [
    "Remove columns so we only have movie name, rating, name of actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8yE_F2X-sRP",
    "outputId": "20377c49-07d4-48ae-f94a-4002102a9289"
   },
   "outputs": [],
   "source": [
    "columns_to_keep = ['movie', 'rating', 'actors']\n",
    "\n",
    "# Drop columns that are not in the 'columns_to_keep' list\n",
    "filtered_movies_df = filtered_movies_df[columns_to_keep]\n",
    "\n",
    "# Display the first few rows of the modified DataFrame\n",
    "filtered_movies_df.head()\n",
    "print(len(filtered_movies_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4On_9UEB_K9N"
   },
   "source": [
    "seems like there's duplicate entries looking at row 2 and 3 of the previous table, let's dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lPL-8CL__m4y",
    "outputId": "e1dd0711-f84f-4d0a-9445-f6d22ecb72e5"
   },
   "outputs": [],
   "source": [
    "filtered_movies_df = filtered_movies_df.drop_duplicates(subset='movie', keep='first')\n",
    "\n",
    "# Display the first few rows of the DataFrame after removing duplicates\n",
    "filtered_movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSyUQTl3gjbZ"
   },
   "source": [
    "That looks better and can be used for analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWhAexdAgW3v"
   },
   "source": [
    "# **EDA part 2: Data Exploring and visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQ-LNlX5_9O3"
   },
   "source": [
    "Now let's create a new table with two columns, actor name and the average rating of all the movies they were in\n",
    "\n",
    "First let's have a dictionary actor_ratings which stores rating info for each actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tu0FssTjANiG"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "# Create an empty dictionary to store the sum and count of ratings for each actor\n",
    "actor_ratings = {}\n",
    "\n",
    "# Iterate through each row of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "  # Extract the list of actors from the 'actors' column\n",
    "  actors_list_str = row['actors']\n",
    "  actors_list_arr = literal_eval(actors_list_str)\n",
    "  row['actors'] = actors_list_arr\n",
    "  # Extract the rating for the movie\n",
    "  rating = row['rating']\n",
    "\n",
    "  # Check if the 'actors' column is a list\n",
    "  if isinstance(actors_list_arr, list):\n",
    "      # Iterate through each actor in the list\n",
    "    for actor in actors_list_arr:\n",
    "      # If the actor is not in the dictionary, add a new entry\n",
    "      if actor not in actor_ratings:\n",
    "          actor_ratings[actor] = {'sum': rating, 'count': 1}\n",
    "      else:\n",
    "          # If the actor is already in the dictionary, update the sum and count\n",
    "          actor_ratings[actor]['sum'] += rating\n",
    "          actor_ratings[actor]['count'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFIk0bVjDGsB"
   },
   "source": [
    "Then let's convert it into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SWNOHNejDI0h",
    "outputId": "460dc206-7d74-4c49-b56d-890b274fa004"
   },
   "outputs": [],
   "source": [
    "# Create a list of dictionaries for actor names and their average ratings\n",
    "data_list = [{'actor_name': actor, 'average_rating': round(data['sum'] / data['count'], 2), 'movie_count': data['count']} for actor, data in actor_ratings.items()]\n",
    "\n",
    "# Create a new DataFrame using pandas.concat\n",
    "average_ratings_df = pd.concat([pd.DataFrame(data_list)])\n",
    "\n",
    "# Drop duplicate rows\n",
    "average_ratings_df = average_ratings_df.drop_duplicates()\n",
    "\n",
    "# Filter actors with more than 10 movies\n",
    "average_ratings_df_filtered = average_ratings_df[average_ratings_df['movie_count'] > 20]\n",
    "\n",
    "# Display the new table with actor names and their average ratings\n",
    "average_ratings_df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bL1ROhNWO3Iq"
   },
   "source": [
    "Top 10 actors/actresses are below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "sXZjDxhBO5NS",
    "outputId": "dd307ea6-04af-4a37-b26e-a70170a790aa"
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'average_rating' in descending order and get the top 10\n",
    "top_10_high_ratings = average_ratings_df_filtered.sort_values(by='average_rating', ascending=False).head(10)\n",
    "\n",
    "# Display the top 10 actors with the highest ratings\n",
    "print(\"Top 10 actors with the highest ratings:\")\n",
    "top_10_high_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoO1W-kqgrPO"
   },
   "source": [
    "Here's Ryan Gosling's number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "OfOFsPhcgqgD",
    "outputId": "1f233a5a-c303-4dc4-d06d-b28faca120f8"
   },
   "outputs": [],
   "source": [
    "average_ratings_df_filtered[average_ratings_df_filtered['actor_name'] == 'Ryan Gosling']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8b64Y8nQo1u"
   },
   "source": [
    "Bottom 10 actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "ovObkWGYQq9g",
    "outputId": "56fccaaf-0750-483f-a960-ee94cf514592"
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'average_rating' in ascending order and get the bottom 10\n",
    "top_10_low_ratings = average_ratings_df_filtered.sort_values(by='average_rating', ascending=True).head(10)\n",
    "\n",
    "# Display the top 10 actors with the highest ratings\n",
    "print(\"Top 10 actors with the lowest ratings:\")\n",
    "top_10_low_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ef-EnR_5cjtA"
   },
   "source": [
    "Let's see the general trend of movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "VYFfhZdpb93g",
    "outputId": "061987bc-7bfd-4ecd-fe95-db0c608f1b60"
   },
   "outputs": [],
   "source": [
    "sns.histplot(x= df['rating'], bins = 10)\n",
    "plt.title('Ratings vs number of movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sLrbrMJcsq-"
   },
   "source": [
    "We can see that the movies are pretty normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baRAa0xrebmz"
   },
   "source": [
    "now let's look at each actor's average movie rating vs their movie counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "f1PWuGVAKsom",
    "outputId": "6433f282-3cf8-4a97-f176-3e34d63e22ea"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=average_ratings_df_filtered['average_rating'], y=average_ratings_df_filtered['movie_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7Z2O6uBKsom"
   },
   "source": [
    "### How accurate are our predictions if we compare it with the actual rating a movie received\n",
    "\n",
    "\n",
    "we want to come up with rating predictions then compare it with the actual rating to see how accurate we are\n",
    "\n",
    "***We first want to look at the relationships between a movie's rating vs the average ratings of every actor in the movie***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FamsJpXiBVgp"
   },
   "source": [
    "Add column to original df where we get the average rating of all the actors in that row by using our dictionary to get the average rating of each actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCXGudi2BVTp"
   },
   "outputs": [],
   "source": [
    "for index, row in average_ratings_df_filtered.iterrows():\n",
    "    actor_name = row['actor_name']\n",
    "    if actor_name in actor_ratings:\n",
    "        actor_ratings[actor_name]['average_rating'] = row['average_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxqYIm9_EGN3"
   },
   "source": [
    "Now let's create a new column for average rating of actors for a movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sZ6qt1BfEJQA",
    "outputId": "6be2f277-df4e-4125-c9c7-05ddc57799f0"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Function to calculate average rating of a list of actors\n",
    "def calculate_avg_rating(actors, actor_ratings):\n",
    "    if isinstance(actors, list) and len(actors) > 0:\n",
    "        valid_ratings = [actor_ratings[actor]['average_rating'] for actor in actors if actor_ratings[actor]['average_rating'] is not None]\n",
    "        if valid_ratings:\n",
    "            return sum(valid_ratings) / len(valid_ratings)\n",
    "    return None\n",
    "\n",
    "# Apply the function to create a new 'avg_rating_of_actors' column\n",
    "df['avg_rating_of_actors'] = df['actors'].apply(lambda actors: calculate_avg_rating(actors, actor_ratings))\n",
    "\n",
    "# Iterate over the DataFrame to clean and update values\n",
    "for index, row in df.iterrows():\n",
    "    # Extract the list of actors from the 'actors' column\n",
    "    actors_list_str = row['actors']\n",
    "    actors_list_arr = ast.literal_eval(actors_list_str)  # Using ast.literal_eval to safely evaluate the string as a Python literal\n",
    "    row['actors'] = actors_list_arr\n",
    "\n",
    "    # Extract the rating for the movie\n",
    "    rating = row['rating']\n",
    "    actor_num = 0\n",
    "    actor_rating = 0\n",
    "\n",
    "    # Check if the 'actors' column is a list\n",
    "    if isinstance(actors_list_arr, list):\n",
    "        for actor in actors_list_arr:\n",
    "            if 'average_rating' in actor_ratings[actor]:\n",
    "                actor_rating += actor_ratings[actor]['average_rating']\n",
    "                actor_num += 1\n",
    "\n",
    "        avg_rating = None\n",
    "        if actor_num > 0:\n",
    "            avg_rating = round(actor_rating / actor_num, 2)\n",
    "\n",
    "        # Update the 'avg_rating_of_actors' column\n",
    "        df.at[index, 'avg_rating_of_actors'] = avg_rating\n",
    "\n",
    "# Drop rows with missing values in 'avg_rating_of_actors' or 'rating'\n",
    "df = df.dropna(subset=['avg_rating_of_actors', 'rating'])\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRhcoeSIA_r4",
    "outputId": "a7fce9a1-8d6f-47d0-de7c-78e769352811"
   },
   "outputs": [],
   "source": [
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Use patsy to create design matrices\n",
    "outcome_1, predictors_1 = patsy.dmatrices('rating ~ avg_rating_of_actors', df)\n",
    "\n",
    "# Create an OLS model\n",
    "mod_1 = sm.OLS(outcome_1, predictors_1)\n",
    "\n",
    "# Fit the model\n",
    "res_1 = mod_1.fit()\n",
    "\n",
    "# Display the summary statistics\n",
    "print(res_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "id": "HC4CIJhlI_nI",
    "outputId": "41881982-e0ff-4c6c-fa08-8a2cfd7ec32d"
   },
   "outputs": [],
   "source": [
    "# Set up the figure size for the plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create a box plot using Seaborn\n",
    "sns.boxplot(x='avg_rating_of_actors', y='rating', data=df, palette='viridis')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Box Plot of avg_rating_of_actors vs. Rating', fontsize=16)\n",
    "\n",
    "# Set the labels for the x and y axes\n",
    "plt.xlabel('avg_rating_of_actors', fontsize=14)\n",
    "plt.ylabel('Rating', fontsize=14)\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Adjust the layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_Vxj5UOnhA7"
   },
   "source": [
    "Let's look at the relationship between average rating of actors in a movie vs the movie's rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "OYHpg9zBIpQi",
    "outputId": "e17bf375-999f-415b-8917-2c1eb2d0268e"
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot using Matplotlib\n",
    "plt.scatter(df['avg_rating_of_actors'], df['rating'])\n",
    "\n",
    "# Set the label for the x-axis\n",
    "plt.xlabel('Average Rating of Actors')\n",
    "\n",
    "# Set the label for the y-axis\n",
    "plt.ylabel('Movie Rating')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Average Rating of Actors vs Movie Rating')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiyS9rLKJU9N"
   },
   "source": [
    "Seems like there are some signs of correlation happening here but is it strong enough?\n",
    "\n",
    "## ***Let's train a linear regression Model***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "1skhjnD4lRzv",
    "outputId": "81aee5b1-f3d2-45d4-eca8-e94d18b94880"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules from scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Extract features (X) and target variable (y) from the DataFrame 'df'\n",
    "X = df['avg_rating_of_actors'].values.reshape(-1, 1)\n",
    "y = df['rating']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot data points and regression line\n",
    "plt.scatter(X_test, y_test, label='Testing Data')    # Plot testing data points\n",
    "plt.plot(X_test, y_pred, color='red', label='Linear Regression')    # Plot regression line\n",
    "plt.xlabel('Average rating of actor')\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Year released vs rating')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Display the coefficient(s) and intercept of the linear regression model\n",
    "print(\"Coefficient(s):\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "# Calculate and display the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbdU7ztcvqKb"
   },
   "source": [
    "**Let's try to make some predictions based on one actor!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIhBL29svO4Q"
   },
   "outputs": [],
   "source": [
    "def One_actor_prediction():\n",
    "    # Prompt user to enter an actor's name\n",
    "    name = input(\"Enter an actor of your choice: \")\n",
    "\n",
    "    # Retrieve the average rating of the specified actor from the DataFrame\n",
    "    score = average_ratings_df_filtered.loc[average_ratings_df_filtered['actor_name'] == name, 'average_rating'].iloc[0]\n",
    "\n",
    "    # Create a list containing the actor's score\n",
    "    score_list = [score]\n",
    "\n",
    "    # Create a list to hold the data points\n",
    "    data_points = [[score]]\n",
    "\n",
    "    # Use the trained model to predict the rating for the specified actor\n",
    "    predictions = model.predict(data_points)\n",
    "\n",
    "    # Return the predicted rating\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zi49XR0Jy-Af",
    "outputId": "12f87f8c-a291-40e4-bf2f-e331759485ee"
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "  prediction = One_actor_prediction()\n",
    "  print(\"Predicted score of this actor:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XF6ZJp5yQQt"
   },
   "source": [
    "This is the prototype of our model and it only takes one datapoint for now, but this will improve and take in more actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uepEQGlsKsom"
   },
   "source": [
    "# **Ethics & Privacy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfWgPrlPKson"
   },
   "source": [
    "As a group of students enrolled at UCSD, we all acknowledge that we have aspects of our lives in common that could create biases in our research, and therefore data. We are all members of Gen Z, students, live/lived in San Diego, privileged enough to receive a high education, etc. These aspects of our lives could create an underlying bias that we need to address. Knowing this, we need to ensure that we are accessing data that reaches beyond our generation and using sources that address movies and actors of all ages and backgrounds, basing their popularity on one designated, impartial scale. Additionally, we chose to use Letterboxd for the rating of the movies in our data sets. We know that half of Letterboxd users are under the age of 35, and more than half are between 16 and 24 (https://variety.com/2023/film/news/letterboxd-martin-scorsese-younger-audience-classic-films-1235804153/). Since we know this to be true, we have decided to make our intentions about being able to predict the movie ratings of only Letterboxd users, meaning mostly Generation Z movie ratings. If this is made clear to the audience, we will avoid a bias, as it is not going to skew the data, but be a clear intention in the research process. We are also aware of the fact that choosing Letterboxd in the first place is likely a result of our generation. This could therefore mean that the scale we are using to rate movies is based more than half on the younger portion of the population. Although this is true, Letterboxd will have an impartial scale and vast amount of data to access. As a warning, we will provide this context to the audience so they are well informed that the ratings may primarily reflect the views of the younger generations, and may not accurately depict how the elder populations feel about the movies.\n",
    "\n",
    "We have intentionally chosen to work with a dataset that is public\n",
    "information accessable from Kaggle to avoid issues with privacy. Since this is a public data set, we will not have to worry about terms of use privacy issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGY4RlH7Kson"
   },
   "source": [
    "# **Team Expectations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xm9_f-nGKson"
   },
   "source": [
    "\n",
    "\n",
    "*   We decide to meet at least once a week when necessary and previously decided upon\n",
    "*   We want to ensure that there is a hybrid meeting system available so group members can join from anywhere\n",
    "*   We want to make sure that deadlines are clearly communicated and that people are gently reminded to meet those deadlines\n",
    "*   Judgment free zone!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JY4jF0XFKson"
   },
   "source": [
    "# **Project Timeline Proposal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "b5UI67I0QSpi",
    "outputId": "66476808-e538-47ef-89bb-c0bb1bbf414a"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('/content/Screenshot 2024-02-25 at 6.31.49 PM.png')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
